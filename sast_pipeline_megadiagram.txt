Durinn SAST Benchmark Pipeline — “Mega” Diagram (Control + Ownership + Artifacts)
================================================================================

Goal of this diagram:
  1) Show *where everything belongs* (ownership / layering)
  2) Show the *one true runtime flow* (scan/benchmark/suite are parameterizations)
  3) Show the *filesystem contract* (what gets written where)

LEGEND
------
[State]            = runtime state
{ loop }           = repeats
-->                = transition
(artifact: path)   = filesystem outputs
(module: ...)      = where the code lives (ownership)
(Boundary)         = architectural boundary / dependency direction


================================================================================
A) OWNERSHIP / LAYERING  (where everything belongs)
================================================================================

+----------------------------------------------------------------------------------+
| (Boundary) CLI / UX layer                                                        |
|  entrypoint: sast_cli.py                                                         |
|  modules: cli/dispatch.py, cli/commands/*.py, cli/ui.py, cli/common.py,           |
|           cli/suite_sources.py                                                   |
|                                                                                  |
|  Responsibilities:                                                               |
|   - Parse CLI args and environment                                               |
|   - Choose mode (scan / benchmark / suite / analyze)                             |
|   - Build CaseSpec / RepoSpec (single-case modes)                                |
|   - Collect “suite inputs” (suite-file, worktrees-root, cases-from CSV, prompts)|
|   - Optional bridge path: repo_url + branch tokens -> bootstrap worktrees         |
|   - Build RunRequest / AnalyzeRequest and call the pipeline facade               |
+------------------------------------------+---------------------------------------+
                                           |
                                           v
+----------------------------------------------------------------------------------+
| (Boundary) Pipeline / Orchestration layer                                        |
|  modules: pipeline/wiring.py          (composition root; loads .env)             |
|           pipeline/pipeline.py        (SASTBenchmarkPipeline facade)             |
|           pipeline/models.py          (RepoSpec / CaseSpec / manifests)          |
|           pipeline/scanners.py        (supported scanners + defaults)            |
|           pipeline/core.py            (build scan_<tool> command lines)          |
|           pipeline/execution/run_case.py    (run_tools implementation)           |
|           pipeline/execution/analyze_mode.py (run_analyze implementation)        |
|           pipeline/suites/*           (suite resolver + layout helpers)          |
|                                                                                  |
|  Responsibilities:                                                               |
|   - Resolve suite inputs -> canonical manifest (suite.json)                      |
|   - Resolve case dirs & ids (filesystem truth; '-' <-> '_' variants)             |
|   - Construct tool commands (core.py)                                            |
|   - Execute tool runs + write suite/case manifests + summary.csv                 |
|   - Invoke optional post-processing analysis (per-case)                          |
+------------------------------------------+---------------------------------------+
                                           |
                                           v
+----------------------------------------------------------------------------------+
| (Boundary) Tool runner layer                                                     |
|  modules: tools/scan_<tool>.py (stable subprocess entrypoints)                   |
|           tools/<tool>/* (runner/normalize helpers)                              |
|           tools/core.py + tools/io.py + tools/normalize/* (shared plumbing)      |
|                                                                                  |
|  Responsibilities:                                                               |
|   - Acquire repo (clone/reuse OR use local --repo-path)                          |
|   - Run the scanner CLI/API (Semgrep/Snyk/Sonar/Aikido/...)                      |
|   - Capture raw output + normalize to a common schema                            |
|   - Write tool-run artifacts in the tool run directory                           |
+------------------------------------------+---------------------------------------+
                                           |
                                           v
+----------------------------------------------------------------------------------+
| (Boundary) Analysis layer                                                        |
|  modules: pipeline/analysis/analyze_suite.py (per-case analysis entrypoint)     |
|           pipeline/analysis/framework/*, pipeline/analysis/stages/*              |
|           pipeline/analysis/exports/*, pipeline/scoring/*                        |
|           pipeline/analysis/qa_calibration_runbook.py (suite-scoped QA helper)  |
|           pipeline/analysis/suite_triage_*.py (dataset/calibration/eval)         |
|                                                                                  |
|  Responsibilities:                                                               |
|   - Read normalized outputs                                                      |
|   - Compute metrics / exports / reports / scoring                                |
|   - Write analysis artifacts under case_dir/analysis                              |
+------------------------------------------+---------------------------------------+
                                           |
                                           v
+----------------------------------------------------------------------------------+
| (Boundary) Contracts / Domain layer                                               |
|  modules: sast_benchmark/domain/* (normalized finding types)                      |
|           sast_benchmark/io/layout.py (paths + run discovery)                     |
|           sast_benchmark/io/run_dir.py (run dir creation)                         |
|                                                                                  |
|  Responsibilities:                                                               |
|   - Define stable filesystem + artifact naming contracts                          |
|   - Provide IO + layout helpers usable by multiple layers                         |
|                                                                                  |
|  NOTE: dependency boundary rule (guardrail):                                     |
|    sast_benchmark/* must NOT import pipeline/* or tools/*                         |
+----------------------------------------------------------------------------------+


================================================================================
B) ONE TRUE RUNTIME FLOW  (modes are parameters)
================================================================================

[START]
  |
  v
[CLI parse + validate args]
  (module: sast_cli.py -> cli/dispatch.py)
  |
  v
[Build Pipeline facade]
  (module: pipeline/wiring.py -> pipeline/pipeline.py)
  |
  v
[Choose MODE]
  |
  +--> (scan)      -> CASES = 1, TOOLS = 1 (analysis skipped)
  +--> (benchmark) -> CASES = 1, TOOLS = N (analysis optional)
  +--> (suite)     -> CASES = M, TOOLS = N (analysis optional)
  \--> (analyze)   -> no scanning; read existing outputs only


---------------------------------------
FLOW FOR scan/benchmark  (single-case)
---------------------------------------

[Build CaseSpec + RunRequest]
  (module: cli/commands/scan.py | cli/commands/benchmark.py)
  |
  v
[pipeline.run(req)]
  (module: pipeline/pipeline.py)
  |
  v
[run_tools(req)]
  (module: pipeline/execution/run_case.py)
  |
  v
[If use_suite=True (default): ensure suite/case dirs + manifests]
  (module: pipeline/suites/bundles.py + pipeline/suites/layout.py)
  (artifact: runs/suites/<suite_id>/suite.json)    (incremental)
  (artifact: runs/suites/<suite_id>/summary.csv)   (incremental)
  (artifact: runs/suites/<suite_id>/cases/<case_id>/case.json)
  (artifact: runs/suites/LATEST)
  |
  v
{ FOR EACH TOOL in scanners }
  |
  v
  [Build scan command]
    (module: pipeline/core.py)
    -> python tools/scan_<tool>.py ...
  |
  v
  [Execute tool entrypoint]
    (module: tools/scan_<tool>.py)
    |
    v
    (tool writes artifacts)
      - raw.*                (scanner-specific: sarif/json/etc.)
      - normalized.json       (cross-tool contract)
      - metadata.json
      - logs/
      - run.json
    (artifact root when use_suite=True):
      runs/suites/<suite_id>/cases/<case_id>/tool_runs/<tool>/<run_id>/
    (artifact root when use_suite=False / --no-suite / --no-bundle):
      runs/<tool>/<repo_name>/<run_id>/   (legacy compatibility)
  |
  v
{ END TOOL LOOP }
  |
  v
[Optional per-case analysis]
  (module: pipeline/analysis/analyze_suite.py + stages/*)
  (artifact: runs/suites/<suite_id>/cases/<case_id>/analysis/*)
  |
  v
[Update suite summary + exit]
  (artifact: runs/suites/<suite_id>/summary.csv)
  |
  v
[EXIT]


---------------------------------------
FLOW FOR suite  (multi-case)
---------------------------------------

[Collect “suite inputs”]
  (module: cli/commands/suite.py + cli/suite_sources.py)
  Inputs may be ANY of:
    - --suite-file (python replay file: SUITE_RAW or SUITE_DEF)
    - --worktrees-root (auto-discover local checkouts => cases)
    - --cases-from (CSV “work order” => cases)
    - (optional bridge) --repo-url + branch tokens -> bootstrap worktrees
    - interactive prompts (build a suite, then optionally write a replay file under:
        runs/suites/<suite_id>/replay/replay_suite.py)
  |
  v
[Resolve suite plan -> suite.json + summary scaffolding]
  (module: pipeline/suites/suite_resolver.py)
  (artifact: runs/suites/<suite_id>/suite.json)
  (artifact: runs/suites/<suite_id>/README.txt)
  (artifact: runs/suites/<suite_id>/summary.csv)
  (artifact: runs/suites/LATEST)
  |
  v
{ FOR EACH CASE in suite.json }
  |
  v
  [Create RunRequest for case]
    (module: cli/commands/suite.py)
  |
  v
  [pipeline.run(req) -> run_tools(req)]
    (module: pipeline/pipeline.py -> pipeline/execution/run_case.py)
    (same tool loop + optional analysis as scan/benchmark)
  |
  v
{ END CASE LOOP }
  |
  v
[Suite complete]
  (summary/index updated under runs/suites/<suite_id>/)
  |
  v
[Optional QA triage calibration runbook]
  (enabled by: --qa-calibration)
  |
  v
  [Build suite triage_dataset.csv]
    (module: pipeline/analysis/suite_triage_dataset.py)
    (artifact: runs/suites/<suite_id>/analysis/_tables/triage_dataset.csv)
  |
  v
  [Build triage_calibration.json]
    (module: pipeline/analysis/suite_triage_calibration.py)
    (artifact: runs/suites/<suite_id>/analysis/triage_calibration.json)
    (artifact: runs/suites/<suite_id>/analysis/_tables/triage_calibration_report.csv)
  |
  v
  [Build triage eval summary]
    (module: pipeline/analysis/suite_triage_eval.py)
    (artifact: runs/suites/<suite_id>/analysis/_tables/triage_eval_summary.json)
  |
  v
  [Re-analyze cases to apply calibration]
    (module: pipeline/execution/analyze_mode.py)
    (artifact: runs/suites/<suite_id>/cases/<case_id>/analysis/_tables/triage_queue.csv)
  |
  v
  [Validate expected artifacts]
    (module: pipeline/analysis/qa_calibration_runbook.py)
    (prints: deterministic PASS/FAIL checklist)
  |
  v
[EXIT]


---------------------------------------
FLOW FOR analyze (post-hoc)
---------------------------------------

(mode=analyze)
  |
  v
[Build AnalyzeRequest]
  (module: cli/commands/analyze.py)
  |
  v
[pipeline.analyze(req)]
  (module: pipeline/pipeline.py)
  |
  v
[Resolve suite/case directory]
  (module: pipeline/suites/layout.py)
  - accepts suite_id='latest' via runs/suites/LATEST
  - case_id resolution tolerates '-' <-> '_' variants
  |
  v
[Discover tool runs + select normalized.json]
  (module: sast_benchmark/io/layout.py + pipeline/execution/analyze_mode.py)
  |
  v
[Run analysis/reporting]
  (artifact: <case_dir>/analysis/* or --out path)
  |
  v
[EXIT]


================================================================================
C) FILESYSTEM CONTRACT (what “correct outputs” look like)
================================================================================

repos/
  <repo_name>/                                # acquired clone (default branch)
  worktrees/<repo_name>/<branch_or_case>/      # recommended for micro-suites

runs/
  suites/<suite_id>/                           # suite layout (preferred)
    README.txt                                 # "start here"
    suite.json                                  # suite manifest (cases, tools, timestamps)
    summary.csv                                 # one row per case
    analysis/                                   # suite-scoped analysis artifacts
      _tables/triage_dataset.csv
      triage_calibration.json
      _tables/triage_calibration_report.csv
      _tables/triage_eval_summary.json
    cases/<case_id>/
      case.json                                 # per-case manifest (what ran)
      tool_runs/<tool>/<run_id>/
        raw.*                                   # scanner-specific
        normalized.json                          # pipeline-common contract
        metadata.json
        logs/
        run.json
      analysis/
        *.csv / *.json / *.md                   # analysis stage outputs
      gt/                                       # optional ground-truth assets
  suites/LATEST                                 # pointer file containing latest suite_id

NOTE: legacy non-suite runs may exist under runs/<tool>/<repo_name>/<run_id>/,
but suite layout (runs/suites/...) is the preferred stable contract for analysis and exports.
